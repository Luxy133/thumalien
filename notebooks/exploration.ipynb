{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thumalien - Notebook d'Exploration\n",
    "\n",
    "**Projet M1 Data & IA** - Détection de Fake News sur Bluesky\n",
    "\n",
    "Ce notebook couvre :\n",
    "1. Connexion et collecte de données via l'API Bluesky\n",
    "2. Exploration et statistiques descriptives\n",
    "3. Prétraitement NLP\n",
    "4. Test du classifieur de fake news\n",
    "5. Test de l'analyseur d'émotions\n",
    "6. Explicabilité\n",
    "7. Suivi énergétique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette='Set2')\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "load_dotenv('../.env')\n",
    "print('Setup OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Connexion à Bluesky et collecte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.collector.bluesky_client import BlueskyCollector\n",
    "\n",
    "handle = os.getenv('BLUESKY_HANDLE')\n",
    "password = os.getenv('BLUESKY_PASSWORD')\n",
    "\n",
    "collector = BlueskyCollector(handle, password)\n",
    "print(f'Connecté en tant que {handle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecte de posts sur plusieurs thématiques\n",
    "queries = ['fake news', 'désinformation', 'santé', 'politique', 'climat']\n",
    "all_posts = []\n",
    "\n",
    "for query in queries:\n",
    "    posts = collector.search_posts(query, lang='fr', limit=30)\n",
    "    for p in posts:\n",
    "        p['query'] = query\n",
    "    all_posts.extend(posts)\n",
    "    print(f'  \"{query}\" : {len(posts)} posts')\n",
    "\n",
    "print(f'\\nTotal collecté : {len(all_posts)} posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en DataFrame\n",
    "df = pd.DataFrame(all_posts)\n",
    "print(f'Shape : {df.shape}')\n",
    "print(f'Colonnes : {list(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Exploration et statistiques descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques de base\n",
    "print('=== Statistiques des posts ===')\n",
    "print(f'Posts uniques (par URI) : {df[\"uri\"].nunique()}')\n",
    "print(f'Auteurs uniques : {df[\"author_handle\"].nunique()}')\n",
    "print(f'\\n--- Engagement ---')\n",
    "for col in ['like_count', 'repost_count', 'reply_count']:\n",
    "    print(f'{col}: mean={df[col].mean():.1f}, median={df[col].median():.0f}, max={df[col].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longueur des textes\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df['text_length'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Nombre de caractères')\n",
    "axes[0].set_ylabel('Fréquence')\n",
    "axes[0].set_title('Distribution de la longueur des posts')\n",
    "axes[0].axvline(df['text_length'].mean(), color='red', linestyle='--', label=f'Moyenne: {df[\"text_length\"].mean():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(df['word_count'], bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Nombre de mots')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "axes[1].set_title('Distribution du nombre de mots')\n",
    "axes[1].axvline(df['word_count'].mean(), color='red', linestyle='--', label=f'Moyenne: {df[\"word_count\"].mean():.0f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition par requête de recherche\n",
    "fig = px.histogram(df, x='query', color='query',\n",
    "                   title='Nombre de posts collectés par thématique',\n",
    "                   labels={'query': 'Thématique', 'count': 'Nombre'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top auteurs\n",
    "top_authors = df['author_handle'].value_counts().head(15)\n",
    "\n",
    "fig = px.bar(x=top_authors.values, y=top_authors.index, orientation='h',\n",
    "             title='Top 15 auteurs les plus actifs',\n",
    "             labels={'x': 'Nombre de posts', 'y': 'Auteur'})\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement par thématique\n",
    "engagement = df.groupby('query')[['like_count', 'repost_count', 'reply_count']].mean()\n",
    "\n",
    "fig = px.bar(engagement, barmode='group',\n",
    "             title='Engagement moyen par thématique',\n",
    "             labels={'value': 'Moyenne', 'variable': 'Type'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Prétraitement NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.text_processor import clean_text, tokenize, preprocess_batch\n",
    "\n",
    "# Exemple sur un post\n",
    "sample = df.iloc[0]\n",
    "print('=== Texte original ===')\n",
    "print(sample['text'])\n",
    "print('\\n=== Texte nettoyé ===')\n",
    "cleaned = clean_text(sample['text'])\n",
    "print(cleaned)\n",
    "print('\\n=== Tokens (lemmes) ===')\n",
    "tokens = tokenize(cleaned, lang='fr')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement du dataset complet\n",
    "posts_list = df.to_dict('records')\n",
    "processed = preprocess_batch(posts_list)\n",
    "\n",
    "df_processed = pd.DataFrame(processed)\n",
    "print(f'Colonnes ajoutées : {[c for c in df_processed.columns if c not in df.columns]}')\n",
    "df_processed[['text', 'clean_text', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mots les plus fréquents\n",
    "all_tokens = [token for tokens in df_processed['tokens'] for token in tokens]\n",
    "token_freq = Counter(all_tokens).most_common(30)\n",
    "\n",
    "words, counts = zip(*token_freq)\n",
    "fig = px.bar(x=list(counts), y=list(words), orientation='h',\n",
    "             title='Top 30 des mots les plus fréquents (après lemmatisation)',\n",
    "             labels={'x': 'Fréquence', 'y': 'Mot'})\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'}, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "\n",
    "    text_all = ' '.join(all_tokens)\n",
    "    wc = WordCloud(width=800, height=400, background_color='white',\n",
    "                   colormap='viridis', max_words=100).generate(text_all)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Wordcloud des posts collectés')\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print('pip install wordcloud pour afficher le nuage de mots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Classification Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.fake_news_detector import FakeNewsDetector\n",
    "\n",
    "detector = FakeNewsDetector()\n",
    "print('Modèle chargé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sur quelques exemples\n",
    "test_texts = [\n",
    "    \"Le président a annoncé de nouvelles mesures économiques lors de la conférence de presse.\",\n",
    "    \"BREAKING: Les extraterrestres ont atterri à Paris, le gouvernement cache la vérité !!!\",\n",
    "    \"Selon l'OMS, le vaccin est sûr et efficace après les essais cliniques de phase 3.\",\n",
    "    \"On vous cache tout ! Les élites contrôlent le monde avec la 5G, réveillez-vous !\",\n",
    "    \"Le match de football s'est terminé par un score de 2-1.\",\n",
    "]\n",
    "\n",
    "print('=== Test du classifieur ===')\n",
    "for text in test_texts:\n",
    "    result = detector.predict(text)\n",
    "    print(f'\\n[{result[\"label\"].upper()}] (confiance: {result[\"confidence\"]:.2%})')\n",
    "    print(f'  Texte: {text[:80]}...')\n",
    "    print(f'  Scores: {result[\"scores\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification de tous les posts collectés\n",
    "texts = df_processed['clean_text'].tolist()\n",
    "predictions = detector.predict_batch(texts)\n",
    "\n",
    "df_processed['cred_label'] = [p['label'] for p in predictions]\n",
    "df_processed['cred_confidence'] = [p['confidence'] for p in predictions]\n",
    "df_processed['cred_scores'] = predictions\n",
    "\n",
    "print('=== Répartition des labels ===')\n",
    "print(df_processed['cred_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la répartition\n",
    "colors = {'fiable': '#2ecc71', 'douteux': '#f39c12', 'fake': '#e74c3c'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "label_counts = df_processed['cred_label'].value_counts()\n",
    "axes[0].pie(label_counts.values, labels=label_counts.index,\n",
    "            colors=[colors[l] for l in label_counts.index],\n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Répartition de la crédibilité')\n",
    "\n",
    "# Histogramme de confiance\n",
    "for label in ['fiable', 'douteux', 'fake']:\n",
    "    subset = df_processed[df_processed['cred_label'] == label]['cred_confidence']\n",
    "    axes[1].hist(subset, bins=15, alpha=0.6, label=label, color=colors[label])\n",
    "axes[1].set_xlabel('Score de confiance')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "axes[1].set_title('Distribution des scores de confiance')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crédibilité par thématique\n",
    "cross = pd.crosstab(df_processed['query'], df_processed['cred_label'], normalize='index') * 100\n",
    "\n",
    "fig = px.bar(cross, barmode='stack',\n",
    "             title='Crédibilité par thématique (%)',\n",
    "             labels={'value': 'Pourcentage', 'query': 'Thématique'},\n",
    "             color_discrete_map=colors)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Analyse émotionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.emotion_analyzer import EmotionAnalyzer\n",
    "\n",
    "emotion_analyzer = EmotionAnalyzer()\n",
    "print('Analyseur d\\'émotions chargé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse émotionnelle de tous les posts\n",
    "emotions = emotion_analyzer.analyze_batch(texts)\n",
    "\n",
    "df_processed['emotion_dominant'] = [e['dominant_emotion'] for e in emotions]\n",
    "df_processed['emotion_confidence'] = [e['confidence'] for e in emotions]\n",
    "df_processed['emotion_scores'] = emotions\n",
    "\n",
    "print('=== Répartition des émotions ===')\n",
    "print(df_processed['emotion_dominant'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des émotions\n",
    "emo_colors = {\n",
    "    'colère': '#e74c3c', 'dégoût': '#8e44ad', 'peur': '#2c3e50',\n",
    "    'joie': '#f1c40f', 'tristesse': '#3498db', 'surprise': '#e67e22', 'neutre': '#95a5a6'\n",
    "}\n",
    "\n",
    "fig = px.histogram(df_processed, x='emotion_dominant', color='emotion_dominant',\n",
    "                   color_discrete_map=emo_colors,\n",
    "                   title='Distribution des émotions dominantes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart : profil émotionnel moyen\n",
    "all_emo_scores = {}\n",
    "for e in emotions:\n",
    "    for emo, score in e['scores'].items():\n",
    "        all_emo_scores.setdefault(emo, []).append(score)\n",
    "\n",
    "avg_emo = {emo: np.mean(vals) for emo, vals in all_emo_scores.items()}\n",
    "\n",
    "fig = go.Figure(data=go.Scatterpolar(\n",
    "    r=list(avg_emo.values()),\n",
    "    theta=list(avg_emo.keys()),\n",
    "    fill='toself'\n",
    "))\n",
    "fig.update_layout(title='Profil émotionnel moyen des posts collectés',\n",
    "                  polar=dict(radialaxis=dict(visible=True, range=[0, 1])))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Croisement émotions x crédibilité\n",
    "fig = px.histogram(df_processed, x='emotion_dominant', color='cred_label',\n",
    "                   color_discrete_map=colors, barmode='group',\n",
    "                   title='Émotions par catégorie de crédibilité')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap émotions x crédibilité\n",
    "cross_emo = pd.crosstab(df_processed['cred_label'], df_processed['emotion_dominant'])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(cross_emo, annot=True, fmt='d', cmap='YlOrRd')\n",
    "plt.title('Heatmap : Crédibilité vs Émotion dominante')\n",
    "plt.xlabel('Émotion')\n",
    "plt.ylabel('Crédibilité')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Explicabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explainability.explainer import PredictionExplainer\n",
    "\n",
    "explainer = PredictionExplainer(detector.model, detector.tokenizer)\n",
    "\n",
    "# Analyser les posts classés \"douteux\" ou \"fake\"\n",
    "suspicious = df_processed[df_processed['cred_label'].isin(['douteux', 'fake'])].head(5)\n",
    "\n",
    "print(f'{len(suspicious)} posts suspects à expliquer\\n')\n",
    "\n",
    "for idx, row in suspicious.iterrows():\n",
    "    explanation = explainer.explain(row['clean_text'])\n",
    "    print(f'--- Post #{idx} [{row[\"cred_label\"].upper()}] ---')\n",
    "    print(f'Texte : {row[\"text\"][:100]}...')\n",
    "    print(f'Émotion : {row[\"emotion_dominant\"]}')\n",
    "    print(f'Top mots influents :')\n",
    "    for w in explanation['top_influential_words'][:5]:\n",
    "        bar = '█' * int(w['importance_normalized'] * 20)\n",
    "        print(f'  {w[\"token\"]:>15s} {bar} ({w[\"importance_normalized\"]:.2f})')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'importance des mots pour un post\n",
    "if len(suspicious) > 0:\n",
    "    sample_text = suspicious.iloc[0]['clean_text']\n",
    "    expl = explainer.explain(sample_text)\n",
    "\n",
    "    top_words = expl['all_word_importances'][:15]\n",
    "    tokens_list = [w['token'] for w in top_words]\n",
    "    importances = [w['importance_normalized'] for w in top_words]\n",
    "\n",
    "    fig = px.bar(x=importances, y=tokens_list, orientation='h',\n",
    "                 title=f'Importance des mots (post classé \"{suspicious.iloc[0][\"cred_label\"]}\")',\n",
    "                 labels={'x': 'Importance normalisée', 'y': 'Token'},\n",
    "                 color=importances, color_continuous_scale='Reds')\n",
    "    fig.update_layout(yaxis={'categoryorder': 'total ascending'}, height=500)\n",
    "    fig.show()\n",
    "else:\n",
    "    print('Aucun post suspect trouvé pour démontrer l\\'explicabilité')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Suivi énergétique (Green IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.monitoring.energy_tracker import EnergyTracker\n",
    "import time\n",
    "\n",
    "tracker = EnergyTracker(output_dir='../data/monitoring')\n",
    "\n",
    "# Mesurer l'énergie d'une classification batch\n",
    "with tracker.track('classification_batch'):\n",
    "    _ = detector.predict_batch(texts[:20])\n",
    "\n",
    "# Mesurer l'énergie d'une analyse émotionnelle\n",
    "with tracker.track('emotion_batch'):\n",
    "    _ = emotion_analyzer.analyze_batch(texts[:20])\n",
    "\n",
    "summary = tracker.get_summary()\n",
    "print('=== Rapport énergétique ===')\n",
    "print(f'Émissions totales  : {summary[\"total_emissions_kg_co2\"]:.6f} kg CO2')\n",
    "print(f'Énergie totale     : {summary[\"total_energy_kwh\"]:.6f} kWh')\n",
    "print(f'Durée totale       : {summary[\"total_duration_seconds\"]:.2f} s')\n",
    "print(f'Nombre de tâches   : {summary[\"num_tasks\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "if summary['tasks']:\n",
    "    task_df = pd.DataFrame(summary['tasks'])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    axes[0].bar(task_df['task'], task_df['duration_seconds'], color=['#3498db', '#e74c3c'])\n",
    "    axes[0].set_ylabel('Durée (secondes)')\n",
    "    axes[0].set_title('Durée par tâche')\n",
    "\n",
    "    axes[1].bar(task_df['task'], task_df['emissions_kg_co2'], color=['#2ecc71', '#f39c12'])\n",
    "    axes[1].set_ylabel('Émissions (kg CO2)')\n",
    "    axes[1].set_title('Émissions CO2 par tâche')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Résumé et export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé global\n",
    "print('=' * 60)\n",
    "print('RÉSUMÉ DE L\\'EXPLORATION')\n",
    "print('=' * 60)\n",
    "print(f'Posts collectés     : {len(df_processed)}')\n",
    "print(f'Auteurs uniques     : {df_processed[\"author_handle\"].nunique()}')\n",
    "print(f'Thématiques         : {\", \".join(queries)}')\n",
    "print(f'\\n--- Crédibilité ---')\n",
    "for label in ['fiable', 'douteux', 'fake']:\n",
    "    count = (df_processed['cred_label'] == label).sum()\n",
    "    pct = count / len(df_processed) * 100\n",
    "    print(f'  {label:>10s} : {count:3d} ({pct:.1f}%)')\n",
    "print(f'\\n--- Émotion dominante la plus fréquente ---')\n",
    "print(f'  {df_processed[\"emotion_dominant\"].mode().iloc[0]}')\n",
    "print(f'\\n--- Énergie ---')\n",
    "print(f'  CO2 : {summary[\"total_emissions_kg_co2\"]:.6f} kg')\n",
    "print(f'  kWh : {summary[\"total_energy_kwh\"]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des résultats d'exploration\n",
    "export_cols = ['author_handle', 'text', 'clean_text', 'query',\n",
    "               'like_count', 'repost_count', 'reply_count',\n",
    "               'cred_label', 'cred_confidence', 'emotion_dominant', 'emotion_confidence']\n",
    "\n",
    "df_export = df_processed[export_cols]\n",
    "df_export.to_csv('../data/processed/exploration_results.csv', index=False, encoding='utf-8')\n",
    "print(f'Résultats exportés : ../data/processed/exploration_results.csv ({len(df_export)} lignes)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
